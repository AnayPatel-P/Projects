# ğŸˆ Predicting College Football Final AP Poll Rankings (2013â€“2023)

This project uses historical NCAA college football statistics to **predict the final AP Poll ranking** for each team using machine learning models. It combines advanced data wrangling, exploratory analysis, and predictive modeling techniques to explore what drives top-ranked college football programs.

---

## ğŸ“¦ Project Summary

- ğŸ“… **Timeframe:** 2013â€“2023
- ğŸ§  **Model:** Random Forest Regressor (with and without RFE feature selection)
- ğŸ“Š **Target:** Final AP Poll Rank (1â€“25)
- ğŸ› **Features:** 100+ team-level stats (offense, defense, turnovers, etc.)
- ğŸ† **Goal:** Understand which features best predict end-of-season rankings

---

## ğŸš€ Highlights

- âœ… Cleaned and merged yearly college football data from 2013 to 2023
- ğŸ· Matched team names with final AP poll rankings across years
- ğŸ› Integrated conference affiliation for each season
- ğŸ“ˆ Conducted in-depth **EDA** (feature distributions, correlation heatmaps, time-series trends)
- ğŸ¤– Trained Random Forest models to predict rankings
- âš™ï¸ Applied **Recursive Feature Elimination (RFE)** for feature selection
- ğŸ“‰ Compared models with and without conference data to assess impact
- ğŸ“ Exported predictions + RMSE scores

---

## ğŸ“ File Structure

```
CFB-RankPredictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cfb20xx.csv (yearly stats)
â”‚   â”œâ”€â”€ Poll 20xx.csv (final poll rankings)
â”‚   â”œâ”€â”€ Conference 20xx.csv (team-conference mapping)
â”œâ”€â”€ cfb_merged_with_conference.csv
â”œâ”€â”€ predicted_vs_actual_rankings.csv
â”œâ”€â”€ predicted_vs_actual_rankings_rfe.csv
â”œâ”€â”€ model_notebook.ipynb
â””â”€â”€ README.md
```

---

## ğŸ” Exploratory Data Analysis (EDA)

- ğŸ“Š Distribution plots: ranked vs unranked teams
- ğŸ”— Top features correlated with final ranking
- ğŸ—º Average ranking per conference
- ğŸ“‰ RMSE trend with and without conference features
- ğŸ“ˆ Time-series line plots for top programs (Alabama, Clemson, OSU, Georgia)

---

## ğŸ§  Modeling

### Model 1: Baseline Random Forest
- **RMSE:** ~5.62
- Input: All numerical + conference one-hot features
- Output: Predicted rank per year (1 = best)

### Model 2: RFE Feature-Selected Random Forest
- **RMSE:** ~5.15
- Reduced input to 30 most predictive features using Recursive Feature Elimination

---

## ğŸ” Feature Importance

Top 15 features (RFE-selected) included:
- Total Points
- Avg Turnover Margin
- Yards Allowed
- Off Yards/Game
- Opponent 3rd % Allowed
- Redzone Points
- Sacks
- Touchdowns Allowed

---

## ğŸ› Conference Analysis

- Slight performance gain (â†“ RMSE) when including conference features
- Average prediction error plotted per conference
- Shows variance in ranking predictability across conferences

---

## ğŸ“ˆ Visualizations

- ğŸ“Š KDE and bar plots comparing ranked/unranked stats
- ğŸ§¯ Correlation heatmaps across 130+ features
- ğŸ“… Year-by-year final rank line plots
- ğŸ” Scatterplots of prediction vs actual rank (with y = x line)
- ğŸ“‰ Bar charts showing RMSE with/without conference info

---

## ğŸ“¤ Outputs

- `cfb_merged_with_conference.csv`: Cleaned master dataset
- `predicted_vs_actual_rankings.csv`: Baseline model predictions
- `predicted_vs_actual_rankings_rfe.csv`: RFE-optimized predictions

---

## ğŸ§ª Evaluation Metric

**Root Mean Squared Error (RMSE)**  
Used to evaluate ranking prediction accuracy year-over-year.

---

## ğŸ“Œ Next Steps

- [ ] Tune hyperparameters with GridSearchCV
- [ ] Try XGBoost or LightGBM for improved accuracy
- [ ] Build a Streamlit app or Power BI dashboard
- [ ] Introduce "momentum" features (e.g., win streak, strength of schedule)

---

## ğŸ‘¨â€ğŸ’» Built By

**Anay Patel**  
[LinkedIn](https://www.linkedin.com/in/anaypatel26) | [GitHub](https://github.com/AnayPatel-P)

---